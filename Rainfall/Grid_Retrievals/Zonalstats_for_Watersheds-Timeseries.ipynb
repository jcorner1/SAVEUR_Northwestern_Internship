{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import wradlib as wrl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from osgeo import osr\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pyart\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import from_levels_and_colors\n",
    "import matplotlib.patches as patches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the radar grid coordinates. These coordinates are in WGS84 CRS.\n",
    "# Getting back the objects:\n",
    "with open('/home/icrisologo/SAVEUR/radar_grid.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "    x_rad, y_rad = pickle.load(f)\n",
    "\n",
    "def testplot(cats, catsavg, xy, data, savefname,\n",
    "             levels=[0, 1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 100, 150],\n",
    "             title=\"\"):\n",
    "    \"\"\"Quick test plot layout for this example file\n",
    "    \"\"\"\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(levels)))\n",
    "    mycmap, mynorm = from_levels_and_colors(levels, colors, extend=\"max\")\n",
    "\n",
    "    radolevels = [0, 1, 2, 3, 4, 5, 10, 15, 20, 25, 30, 40, 50, 100, 150]\n",
    "    radocolors = pyart.graph.cm_colorblind.HomeyerRainbow(np.linspace(0, 1, len(radolevels)))\n",
    "    #pyart.graph.cm_colorblind()\n",
    "    radocmap, radonorm = from_levels_and_colors(radolevels, radocolors,\n",
    "                                                extend=\"max\")\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "\n",
    "    # Average rainfall sum\n",
    "    ax = fig.add_subplot(122, aspect=\"equal\")\n",
    "    coll = PatchCollection(cats, array=catsavg, cmap=radocmap, norm=mynorm,\n",
    "                           edgecolors='white', lw=0.5)\n",
    "    ax.add_collection(coll)\n",
    "    ax.autoscale()\n",
    "    plt.colorbar(coll, ax=ax, shrink=0.5)\n",
    "    plt.xlabel(\"NAD83 Z16 Easting\")\n",
    "    plt.ylabel(\"NAD83 Z16 Northing\")\n",
    "    plt.title(title)\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "    # Original radar data\n",
    "    ax1 = fig.add_subplot(121, aspect=\"equal\")\n",
    "    pm = plt.pcolormesh(xy[:, :, 0], xy[:, :, 1], np.ma.masked_invalid(data),\n",
    "                        cmap=radocmap, norm=radonorm)\n",
    "    coll = PatchCollection(cats, facecolor='None', edgecolor='k', lw=0.1)\n",
    "    ax1.add_collection(coll)\n",
    "    cb = plt.colorbar(pm, ax=ax1, shrink=0.5)\n",
    "    cb.set_label(\"(mm/h)\")\n",
    "    plt.xlabel(\"NAD83 Z16 Easting\")\n",
    "    plt.ylabel(\"NAD83 Z16 Northing\")\n",
    "    plt.title(\"Original radar rain sums: \" + savefname.strip('.png'))\n",
    "    ax1.set_xlim(bbox['left']-10000,bbox['right']+10000)\n",
    "    ax1.set_ylim(bbox['bottom']-10000,bbox['top']+10000)\n",
    "    #plt.draw()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(savefname)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the watershed shapefile.\n",
    "# this file is in UTM\n",
    "fname_shp = '/home/icrisologo/Data/city_detailed_utm.shp'\n",
    "\n",
    "dataset, inLayer = wrl.io.open_vector(fname_shp)\n",
    "borders, keys = wrl.georef.get_vector_coordinates(inLayer, key='node_id')\n",
    "\n",
    "\n",
    "# Define different projections that will be used in the processing.\n",
    "\n",
    "proj_wgs = osr.SpatialReference()\n",
    "proj_wgs.ImportFromEPSG(4326)\n",
    "\n",
    "proj_aeqd = osr.SpatialReference()\n",
    "proj_aeqd.ImportFromEPSG(54032)\n",
    "\n",
    "proj_IL = osr.SpatialReference()\n",
    "proj_IL.ImportFromEPSG(26771)\n",
    "\n",
    "proj_IL_UTM = osr.SpatialReference()\n",
    "proj_IL_UTM.ImportFromEPSG(26916)\n",
    "\n",
    "\n",
    "# Put the two coordinate grids in one array.\n",
    "\n",
    "grid_xy = np.zeros((300,300,2))\n",
    "\n",
    "grid_xy[:,:,0] = x_rad\n",
    "grid_xy[:,:,1] = y_rad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the radar grid to UTM, to match the shapefile.\n",
    "\n",
    "grid_xy_utm = wrl.georef.reproject(grid_xy,\n",
    "                                projection_source=proj_wgs,\n",
    "                                projection_target=proj_IL_UTM)\n",
    "\n",
    "x_rad_utm = grid_xy_utm[:,:,0]\n",
    "y_rad_utm = grid_xy_utm[:,:,1]\n",
    "\n",
    "\n",
    "# Create a mask to reduce size.\n",
    "\n",
    "# Reduce grid size using a bounding box (to enhancing performance)\n",
    "bbox = inLayer.GetExtent()\n",
    "\n",
    "buffer = 5000.\n",
    "bbox = dict(left=bbox[0] - buffer, right=bbox[1] + buffer,\n",
    "            bottom=bbox[2] - buffer, top=bbox[3] + buffer)\n",
    "mask = (((grid_xy_utm[..., 1] > bbox['bottom']) & (grid_xy_utm[..., 1] < bbox['top'])) &\n",
    "        ((grid_xy_utm[..., 0] > bbox['left']) & (grid_xy_utm[..., 0] < bbox['right'])))\n",
    "\n",
    "# Create vertices for each grid cell\n",
    "# (MUST BE DONE IN NATIVE COORDINATES)\n",
    "\n",
    "grdverts = wrl.zonalstats.grid_centers_to_vertices(x_rad_utm[mask],\n",
    "                                                   y_rad_utm[mask], 824,\n",
    "                                                   824)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of type ZonalDataPoly from source grid and catchment array. This needs to be done only once, then dump to file. The files that will be saved are the `src` shapefile (radar pixels), `trg` shapefile (original catchment), and `dst` shapefile (the radar pixels cut according to `trg`).\n",
    "\n",
    "# Create instance of type ZonalDataPoly from source grid and\n",
    "# catchment array\n",
    "zd = wrl.zonalstats.ZonalDataPoly(grdverts, borders)\n",
    "\n",
    "# dump to file\n",
    "zd.dump_vector('zonal_poly_cart_test')\n",
    "\n",
    "# Create instance of type ZonalStatsPoint from zonal data object\n",
    "obj3 = wrl.zonalstats.ZonalStatsPoly(zd)\n",
    "\n",
    "\n",
    "# ### Now the looping can happen\n",
    "\n",
    "# Read the gridded data.\n",
    "#datefolder = '2013/06/26'\n",
    "datefolder = sys.argv[1]\n",
    "file_dir = \"/lcrc/group/earthscience/icrisologo/SAVEUR/gridded/\"+datefolder+\"/\"\n",
    "gridded_files = glob.glob(file_dir+'*')\n",
    "gridded_files.sort()\n",
    "\n",
    "\n",
    "df_rZ = pd.DataFrame()\n",
    "f = gridded_files[0]\n",
    "grid = pyart.io.read_grid(f)\n",
    "\n",
    "data_rZ = grid.fields['radar_rainfall_depth_rainrate']['data'].squeeze()#[mask] # mask data to reduce size\n",
    "data_rZ_ = data_rZ[mask]\n",
    "\n",
    "\n",
    "# Compute stats for target polygons\n",
    "avg_rZ = obj3.mean(data_rZ_.ravel())\n",
    "\n",
    "# Target polygon patches\n",
    "trg_patches = [patches.Polygon(item, True) for item in obj3.zdata.trg.data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get time\n",
    "dtime = str(dt.datetime.strptime(f.rsplit('/')[-1].rsplit('.')[0],'radar_KLOT_%Y%m%d_%H%M%S_gridded'))\n",
    "# put to dataframe\n",
    "df_rZ_ = pd.DataFrame(data=[avg_rZ],columns=keys)\n",
    "\n",
    "df_rZ_['DateTime'] = dtime\n",
    "\n",
    "df_rZ = df_rZ.append(df_rZ_)\n",
    "\n",
    "# set save filename\n",
    "savefname_rZ = f.rsplit('/')[-1].rsplit('.')[0]+'_rZ.png'\n",
    "\n",
    "# plot\n",
    "testplot(trg_patches, avg_rZ, grid_xy_utm, data_rZ, savefname_rZ,\n",
    "     title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dataframe where we will put the extracted values\n",
    "df_rZ = pd.DataFrame()\n",
    "df_rA = pd.DataFrame()\n",
    "df_rKDP = pd.DataFrame()\n",
    "df_rZ_RT = pd.DataFrame()\n",
    "df_rZ_MP = pd.DataFrame()\n",
    "df_rZ_WC = pd.DataFrame()\n",
    "\n",
    "for f in gridded_files:\n",
    "    print(f)\n",
    "    grid = pyart.io.read_grid(f)\n",
    "\n",
    "    data_rZ = grid.fields['radar_rainfall_depth_rainrate']['data'].squeeze()\n",
    "    data_rA = grid.fields['radar_rainfall_depth_rainrate_from_attenuation']['data'].squeeze()\n",
    "    data_rKDP = grid.fields['radar_rainfall_depth_rainrate_from_kdp']['data'].squeeze()\n",
    "    data_rZ_RT = grid.fields['radar_rainfall_depth_rainrate_z_RT']['data'].squeeze()\n",
    "    data_rZ_MP = grid.fields['radar_rainfall_depth_rainrate_z_MP']['data'].squeeze()\n",
    "    data_rZ_WC = grid.fields['radar_rainfall_depth_rainrate_z_WC']['data'].squeeze()\n",
    "\n",
    "    # mask data to reduce size\n",
    "    data_rZ_ = data_rZ[mask]\n",
    "    data_rA_ = data_rA[mask]\n",
    "    data_rKDP_ = data_rKDP[mask]\n",
    "    data_rZ_RT_ = data_rZ_RT[mask]\n",
    "    data_rZ_MP_ = data_rZ_MP[mask]\n",
    "    data_rZ_WC_ = data_rZ_WC[mask]\n",
    "\n",
    "    # Compute stats for target polygons\n",
    "    avg_rZ = obj3.mean(data_rZ_.ravel())\n",
    "    avg_rA = obj3.mean(data_rA_.ravel())\n",
    "    avg_rKDP = obj3.mean(data_rKDP_.ravel())\n",
    "    avg_rZ_RT = obj3.mean(data_rZ_RT_.ravel())\n",
    "    avg_rZ_MP = obj3.mean(data_rZ_MP_.ravel())\n",
    "    avg_rZ_WC = obj3.mean(data_rZ_WC_.ravel())\n",
    "\n",
    "\n",
    "    # Target polygon patches\n",
    "    trg_patches = [patches.Polygon(item, True) for item in obj3.zdata.trg.data]\n",
    "\n",
    "    # get time\n",
    "    dtime = str(dt.datetime.strptime(f.rsplit('/')[-1].rsplit('.')[0],'radar_KLOT_%Y%m%d_%H%M%S_gridded'))\n",
    "    # put to dataframe\n",
    "    df_rZ_ = pd.DataFrame(data=[avg_rZ],columns=keys)\n",
    "    df_rA_ = pd.DataFrame(data=[avg_rA],columns=keys)\n",
    "    df_rKDP_ = pd.DataFrame(data=[avg_rKDP],columns=keys)\n",
    "    df_rZ_RT_ = pd.DataFrame(data=[avg_rZ_RT],columns=keys)\n",
    "    df_rZ_MP_ = pd.DataFrame(data=[avg_rZ_MP],columns=keys)\n",
    "    df_rZ_WC_ = pd.DataFrame(data=[avg_rZ_WC],columns=keys)\n",
    "\n",
    "    df_rZ_['DateTime'] = dtime\n",
    "    df_rA_['DateTime'] = dtime\n",
    "    df_rKDP_['DateTime'] = dtime\n",
    "    df_rZ_RT_['DateTime'] = dtime\n",
    "    df_rZ_MP_['DateTime'] = dtime\n",
    "    df_rZ_WC_['DateTime'] = dtime\n",
    "\n",
    "    df_rZ = df_rZ.append(df_rZ_)\n",
    "    df_rA = df_rA.append(df_rA_)\n",
    "    df_rKDP = df_rKDP.append(df_rKDP_)\n",
    "    df_rZ_RT = df_rZ_RT.append(df_rZ_RT_)\n",
    "    df_rZ_MP = df_rZ_MP.append(df_rZ_MP_)\n",
    "    df_rZ_WC = df_rZ_WC.append(df_rZ_WC_)\n",
    "\n",
    "    # set save filename\n",
    "    savefname_rZ = f.rsplit('/')[-1].rsplit('.')[0]+'_rZ.png'\n",
    "    savefname_rA = f.rsplit('/')[-1].rsplit('.')[0]+'_rA.png'\n",
    "    savefname_rKDP = f.rsplit('/')[-1].rsplit('.')[0]+'_rKDP.png'\n",
    "    savefname_rZ_RT = f.rsplit('/')[-1].rsplit('.')[0]+'_rZ_RT.png'\n",
    "    savefname_rZ_MP = f.rsplit('/')[-1].rsplit('.')[0]+'_rZ_MP.png'\n",
    "    savefname_rZ_WC = f.rsplit('/')[-1].rsplit('.')[0]+'_rZ_WC.png'\n",
    "\n",
    "    # plot\n",
    "    testplot(trg_patches, avg_rZ, grid_xy_utm, data_rZ, savefname_rZ,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "    testplot(trg_patches, avg_rA, grid_xy_utm, data_rA, savefname_rA,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "    testplot(trg_patches, avg_rKDP, grid_xy_utm, data_rKDP, savefname_rKDP,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "    testplot(trg_patches, avg_rZ_RT, grid_xy_utm, data_rZ_RT, savefname_rZ_RT,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "    testplot(trg_patches, avg_rZ_MP, grid_xy_utm, data_rZ, savefname_rZ_MP,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "    testplot(trg_patches, avg_rZ_WC, grid_xy_utm, data_rZ, savefname_rZ_WC,\n",
    "         title=\"Catchment rainfall mean (ZonalStatsPoly)\")\n",
    "\n",
    "\n",
    "datestr = dt.datetime.strftime(dt.datetime.strptime(dtime,'%Y-%m-%d %H:%M:%S').date(),'%Y%m%d')\n",
    "\n",
    "df_rZ.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rZ.csv')\n",
    "df_rA.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rA.csv')\n",
    "df_rKDP.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rKDP.csv')\n",
    "df_rZ_RT.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rZ_RT.csv')\n",
    "df_rZ_MP.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rZ_MP.csv')\n",
    "df_rZ_WC.to_csv('case_study_01_'+datestr+'_hourlyrainfall_chicago_catchments_NODEIDS_rZ_WC.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
